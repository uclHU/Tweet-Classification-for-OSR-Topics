{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b48282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/c2qvpcbd0gd8_v20qfl318fh0000gn/T/ipykernel_25512/2201995998.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.text[i] = output.strip()\n"
     ]
    }
   ],
   "source": [
    "# generate osr_tweets_without_T_U_U.csv\n",
    "# the output dataset keeps 20 topics, but is filtered with hashtag, username and url\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"./osr_tweets_origin.csv\", engine='python')\n",
    "for i in range(len(df.text)):\n",
    "    Tweet = df.text[i]\n",
    "    temp = re.sub('(@[\\w]+\\s[\\w]+\\s@)|(@[\\w]+\\s[\\w]+\\s[\\w]+\\s@)', '@', Tweet)\n",
    "\n",
    "    output = re.sub(\"(#[^\\s]+)|(@[^\\s]+)|(\\w+:\\/\\/\\S+)\",\" \",temp)\n",
    "    output = re.sub('@\\s[\\w]+', '', output)\n",
    "    output = re.sub('\\s+', ' ', output)\n",
    "    df.text[i] = output.strip()\n",
    "\n",
    "file_name = \"./osr_tweets_without_T_U_U.csv\"\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "581a636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/c2qvpcbd0gd8_v20qfl318fh0000gn/T/ipykernel_49179/2898695752.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels.iloc[i] = cur_id\n",
      "/var/folders/zr/c2qvpcbd0gd8_v20qfl318fh0000gn/T/ipykernel_49179/2898695752.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels.iloc[i] = merged_id2label[new_id]\n"
     ]
    }
   ],
   "source": [
    "# generate osr_tweets_origin_v2\n",
    "# the output file is not preprocessed, but the number of various topics is reduced to 8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"./osr_tweets_origin_v2.csv\", engine='python')\n",
    "\n",
    "#remove redundant records\n",
    "redundant_topic = ['Ukraine']\n",
    "df = df[~df['topic'].isin(redundant_topic)]\n",
    "\n",
    "#convert to list\n",
    "docs = df.text\n",
    "\n",
    "labels = df.topic\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "id_counter = 0\n",
    "for i in range(len(labels)):\n",
    "    label = labels.iloc[i]\n",
    "    if label not in label2id:\n",
    "        label2id[label] = id_counter\n",
    "        id_counter += 1\n",
    "\n",
    "for label, id in label2id.items():\n",
    "    id2label[id] = label\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    topic = labels.iloc[i]\n",
    "    cur_id = label2id[topic]\n",
    "    labels.iloc[i] = cur_id\n",
    "\n",
    "merged_label2id = {'Children Education and Skills': 0 \\\n",
    ", 'Health and Social Care': 1\\\n",
    ", 'Crime and Security': 2\\\n",
    ", 'Economy': 3\\\n",
    ", 'Housing Planning and Local Services': 4\\\n",
    ", 'Labour Market and Welfare': 5\\\n",
    ", 'Population and Society': 6\\\n",
    ", 'Transport Environment and Climate Change': 7}\n",
    "\n",
    "merged_id2label = {}\n",
    "for label, idx_id in merged_label2id.items():\n",
    "    merged_id2label[idx_id] = label\n",
    "    id_counter+=1\n",
    "\n",
    "def get_merged_id(pre_id):\n",
    "    if pre_id == 0: return 6\n",
    "    if pre_id == 1: return 0\n",
    "    if pre_id == 2: return 5\n",
    "    if pre_id == 3: return 1\n",
    "    if pre_id == 4: return 2\n",
    "    if pre_id == 5: return 7\n",
    "    if pre_id == 6: return 7\n",
    "    if pre_id == 7: return 3\n",
    "    if pre_id == 8: return 6\n",
    "    if pre_id == 9: return 0\n",
    "    if pre_id == 10: return 7\n",
    "    if pre_id == 11: return 6\n",
    "    if pre_id == 12: return 1\n",
    "    if pre_id == 13: return 4\n",
    "    if pre_id == 14: return 6\n",
    "    if pre_id == 15: return 6\n",
    "    if pre_id == 16: return 0\n",
    "    if pre_id == 17: return 1\n",
    "    if pre_id == 18: return 5\n",
    "    else: return -1\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    pre_id = labels.iloc[i]\n",
    "    new_id = get_merged_id(pre_id)\n",
    "    if not new_id == -1:\n",
    "        labels.iloc[i] = merged_id2label[new_id]\n",
    "        \n",
    "file_name = \"./osr_tweets_origin_v2.csv\"\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60f13e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/c2qvpcbd0gd8_v20qfl318fh0000gn/T/ipykernel_49179/2004722351.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels.iloc[i] = cur_id\n",
      "/var/folders/zr/c2qvpcbd0gd8_v20qfl318fh0000gn/T/ipykernel_49179/2004722351.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels.iloc[i] = merged_id2label[new_id]\n"
     ]
    }
   ],
   "source": [
    "# generate osr_tweets_without_T_U_U_v2\n",
    "# the output file is preprocessed with removal of hashtag, url and username, and the number of various topics is reduced to 8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./osr_tweets_without_T_U_U.csv\", engine='python')\n",
    "\n",
    "#remove redundant records\n",
    "redundant_topic = ['Ukraine']\n",
    "df = df[~df['topic'].isin(redundant_topic)]\n",
    "\n",
    "#convert to list\n",
    "docs = df.text\n",
    "\n",
    "labels = df.topic\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "id_counter = 0\n",
    "for i in range(len(labels)):\n",
    "    label = labels.iloc[i]\n",
    "    if label not in label2id:\n",
    "        label2id[label] = id_counter\n",
    "        id_counter += 1\n",
    "\n",
    "for label, id in label2id.items():\n",
    "    id2label[id] = label\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    topic = labels.iloc[i]\n",
    "    cur_id = label2id[topic]\n",
    "    labels.iloc[i] = cur_id\n",
    "\n",
    "merged_label2id = {'Children Education and Skills': 0 \\\n",
    ", 'Health and Social Care': 1\\\n",
    ", 'Crime and Security': 2\\\n",
    ", 'Economy': 3\\\n",
    ", 'Housing Planning and Local Services': 4\\\n",
    ", 'Labour Market and Welfare': 5\\\n",
    ", 'Population and Society': 6\\\n",
    ", 'Transport Environment and Climate Change': 7}\n",
    "\n",
    "merged_id2label = {}\n",
    "for label, idx_id in merged_label2id.items():\n",
    "    merged_id2label[idx_id] = label\n",
    "    id_counter+=1\n",
    "\n",
    "def get_merged_id(pre_id):\n",
    "    if pre_id == 0: return 6\n",
    "    if pre_id == 1: return 0\n",
    "    if pre_id == 2: return 5\n",
    "    if pre_id == 3: return 1\n",
    "    if pre_id == 4: return 2\n",
    "    if pre_id == 5: return 7\n",
    "    if pre_id == 6: return 7\n",
    "    if pre_id == 7: return 3\n",
    "    if pre_id == 8: return 6\n",
    "    if pre_id == 9: return 0\n",
    "    if pre_id == 10: return 7\n",
    "    if pre_id == 11: return 6\n",
    "    if pre_id == 12: return 1\n",
    "    if pre_id == 13: return 4\n",
    "    if pre_id == 14: return 6\n",
    "    if pre_id == 15: return 6\n",
    "    if pre_id == 16: return 0\n",
    "    if pre_id == 17: return 1\n",
    "    if pre_id == 18: return 5\n",
    "    else: return -1\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    pre_id = labels.iloc[i]\n",
    "    new_id = get_merged_id(pre_id)\n",
    "    if not new_id == -1:\n",
    "        labels.iloc[i] = merged_id2label[new_id]\n",
    "        \n",
    "file_name = \"./osr_tweets_without_T_U_U_v2.csv\"\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate osr_tweets_origin_v2\n",
    "# the output file is filtered with stop words, and the number of various topics is reduced to 8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./osr_tweets_without_S_T_U_U.csv\", engine='python')\n",
    "\n",
    "#remove redundant records\n",
    "redundant_topic = ['Ukraine']\n",
    "df = df[~df['topic'].isin(redundant_topic)]\n",
    "\n",
    "#convert to list\n",
    "docs = df.text\n",
    "\n",
    "labels = df.topic\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "id_counter = 0\n",
    "for i in range(len(labels)):\n",
    "    label = labels.iloc[i]\n",
    "    if label not in label2id:\n",
    "        label2id[label] = id_counter\n",
    "        id_counter += 1\n",
    "\n",
    "for label, id in label2id.items():\n",
    "    id2label[id] = label\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    topic = labels.iloc[i]\n",
    "    cur_id = label2id[topic]\n",
    "    labels.iloc[i] = cur_id\n",
    "\n",
    "merged_label2id = {'Children Education and Skills': 0 \\\n",
    ", 'Health and Social Care': 1\\\n",
    ", 'Crime and Security': 2\\\n",
    ", 'Economy': 3\\\n",
    ", 'Housing Planning and Local Services': 4\\\n",
    ", 'Labour Market and Welfare': 5\\\n",
    ", 'Population and Society': 6\\\n",
    ", 'Transport Environment and Climate Change': 7}\n",
    "\n",
    "merged_id2label = {}\n",
    "for label, idx_id in merged_label2id.items():\n",
    "    merged_id2label[idx_id] = label\n",
    "    id_counter+=1\n",
    "\n",
    "def get_merged_id(pre_id):\n",
    "    if pre_id == 0: return 6\n",
    "    if pre_id == 1: return 0\n",
    "    if pre_id == 2: return 5\n",
    "    if pre_id == 3: return 1\n",
    "    if pre_id == 4: return 2\n",
    "    if pre_id == 5: return 7\n",
    "    if pre_id == 6: return 7\n",
    "    if pre_id == 7: return 3\n",
    "    if pre_id == 8: return 6\n",
    "    if pre_id == 9: return 0\n",
    "    if pre_id == 10: return 7\n",
    "    if pre_id == 11: return 6\n",
    "    if pre_id == 12: return 1\n",
    "    if pre_id == 13: return 4\n",
    "    if pre_id == 14: return 6\n",
    "    if pre_id == 15: return 6\n",
    "    if pre_id == 16: return 0\n",
    "    if pre_id == 17: return 1\n",
    "    if pre_id == 18: return 5\n",
    "    else: return -1\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    pre_id = labels.iloc[i]\n",
    "    new_id = get_merged_id(pre_id)\n",
    "    if not new_id == -1:\n",
    "        labels.iloc[i] = merged_id2label[new_id]\n",
    "        \n",
    "file_name = \"./osr_tweets_without_S_T_U_U_v2.csv\"\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c59434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "unzip:  cannot find or open /usr/share/nltk_data/corpora/wordnet.zip, /usr/share/nltk_data/corpora/wordnet.zip.zip or /usr/share/nltk_data/corpora/wordnet.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "# load nltk.stem package\n",
    "\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d3a212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/c2qvpcbd0gd8_v20qfl318fh0000gn/T/ipykernel_49179/694741221.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.text[i] = ' '.join([lemmatizer.lemmatize(word) for word in output.lower().split() if word not in stopwords.words(\"english\")])\n"
     ]
    }
   ],
   "source": [
    "# generate osr_tweets_without_S_T_U_U.csv\n",
    "# the output file is filtered with stop words and is also lemmatized \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df = pd.read_csv(\"./osr_tweets_origin.csv\", engine='python')\n",
    "for i in range(len(df.text)):\n",
    "    Tweet = df.text[i]\n",
    "    temp = re.sub('(@[\\w]+\\s[\\w]+\\s@)|(@[\\w]+\\s[\\w]+\\s[\\w]+\\s@)', '@', Tweet)\n",
    "\n",
    "    output = re.sub(\"(#[^\\s]+)|(@[^\\s]+)|(\\w+:\\/\\/\\S+)\",\" \",temp)\n",
    "    output = re.sub('@\\s[\\w]+', '', output)\n",
    "    output = re.sub('\\s+', ' ', output)\n",
    "    output = output.strip()\n",
    "    df.text[i] = ' '.join([lemmatizer.lemmatize(word) for word in output.lower().split() if word not in stopwords.words(\"english\")])\n",
    "        \n",
    "file_name = \"./osr_tweets_without_S_T_U_U.csv\"\n",
    "df = df[df['text'].map(len) >= 10]\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c0cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 2)\n"
     ]
    }
   ],
   "source": [
    "# generate gpt_tweets_without_T_U_U.csv\n",
    "# the write in file is processed with hashtag, url and username\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./gpt_tweets_origin.csv\", engine='python')\n",
    "df.dropna()\n",
    "for i in range(len(df.text)):\n",
    "    Tweet = df.text.iloc[i]\n",
    "    output = re.sub('(@[\\w]+\\s[\\w]+\\s@)|(@[\\w]+\\s[\\w]+\\s[\\w]+\\s@)', '@', Tweet)\n",
    "\n",
    "    output = re.sub(\"(#[^\\s]+)|(@[^\\s]+)|(\\w+:\\/\\/\\S+)\",\" \",output)\n",
    "    output = re.sub('@\\s[\\w]+', '', output)\n",
    "    output = re.sub('\\s+', ' ', output)\n",
    "    output = re.sub('Children,', 'Children', output)\n",
    "    output = re.sub(', ', ',', output)\n",
    "    df.text.iloc[i] = output.strip()\n",
    "\n",
    "    topic = df.topic.iloc[i]\n",
    "    output = re.sub('Children,', 'Children', topic)\n",
    "    output = re.sub(', ', ',', output)\n",
    "    df.topic.iloc[i] = output.strip()\n",
    "\n",
    "file_name = \"./gpt_tweets_without_T_U_U.csv\"\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
